{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xt = tx1 + (1 − t)x0 `              \n",
    "\n",
    " This equation represents a linear interpolation between two points x0 and x1 using a parameter t.\n",
    "\n",
    "The variable xt is the interpolated point between x0 and x1. t is the interpolation parameter that ranges from 0 to 1.\n",
    "\n",
    "When t=0, xt = x0, meaning xt is equal to the first point x0. \n",
    "\n",
    "When t=1, xt = x1, meaning xt is equal to the second point x1.\n",
    "\n",
    "For values of t between 0 and 1, xt is a linear combination of x0 and x1. Specifically, xt is equal to x0 multiplied by (1 - t) plus x1 multiplied by t. \n",
    "\n",
    "As t increases from 0 to 1, the interpolated point xt moves linearly from x0 to x1 along the line segment between those two points. This allows you to find intermediate points along a straight line path between x0 and x1.\n",
    "\n",
    "In summary, this equation performs linear interpolation between two endpoints based on a parameter t. By varying t from 0 to 1, xt moves uniformly along the straight line path between x0 and x1.\n",
    "\n",
    "\n",
    "`xt ∼ N (tx1, (1 − t)2I),`\n",
    "\n",
    " This notation represents a normal (Gaussian) distribution with the following properties:\n",
    "\n",
    "- xt is a random vector of variables that is normally distributed.\n",
    "- The mean of xt is tx1, where t is a scalar and x1 is a fixed vector. So the mean scales linearly with t.\n",
    "- The covariance matrix is (1 - t)2I, where I is the identity matrix. So the covariance scales quadratically with (1 - t). \n",
    "- As t increases, the variance decreases quadratically towards 0. When t=1, the variance is 0 and xt collapses to the fixed vector x1.\n",
    "- As t decreases towards 0, the variance increases quadratically, spreading out the distribution.\n",
    "\n",
    "In summary, xt interpolates between a fixed vector x1 and a normal distribution with increasing variance as t goes from 1 to 0. The parameter t controls how close xt sticks to the fixed mean x1 versus being spread out.\n",
    "\n",
    "\n",
    "`xt = tx1 ⊕ (1 − t) Down(x0, 2K ),`\n",
    "\n",
    " This equation is calculating a new image xt by combining two existing images x0 and x1 using a weighted average.\n",
    "\n",
    "Specifically:\n",
    "\n",
    "- tx1 represents image x1 weighted by a factor t. So if t=0.5, this would be 0.5 * x1.\n",
    "\n",
    "- (1 - t) Down(x0, 2K) represents image x0 downscaled by a factor of 2K (reducing resolution), weighted by (1 - t). So if t=0.5, this would be 0.5 * Down(x0, 2K). \n",
    "\n",
    "- The ⊕ symbol represents element-wise addition of the two weighted images. \n",
    "\n",
    "So in summary, xt is computed by taking a weighted average of x1 and a downscaled version of x0, controlled by the weighting factor t. This has the effect of transitioning smoothly from x0 to x1 as t goes from 0 to 1, while matching resolutions by downscaling x0. The downscaling of x0 avoids artifacts when combining images of different sizes.\n",
    "\n",
    "\n",
    "`xt = t′ Down(xek , 2k) + (1 − t′) Up(Down(xsk , 2k+1)),`\n",
    "\n",
    "\n",
    " This equation defines xt as a weighted combination of two downsampled images xek and xsk.\n",
    "\n",
    "Specifically:\n",
    "- xek is downsampled by a factor of 2k \n",
    "- xsk is downsampled by a factor of 2k+1 and then upsampled back to the original size\n",
    "- t' is a weighting factor between 0 and 1\n",
    "- xt is computed as:\n",
    "    - t' * Downsampled xek \n",
    "    + (1 - t') * Upsampled downsampled xsk\n",
    "\n",
    "So xt is a mixture of a mildly and heavily downsampled version of the input images, with relative weighting determined by t'. This has the effect of producing a smoothed/blurred combination of the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))\n",
      "tensor([[[[-2.8445e+00,  5.1145e-01, -1.2006e+00, -1.6100e+00,  5.1081e-01,\n",
      "           -1.4714e+00, -8.5396e-01,  4.5243e-01,  1.2125e+00,  1.1608e+00],\n",
      "          [-5.6500e-01,  7.6027e-01, -8.7526e-01, -1.3108e-02,  2.3209e-01,\n",
      "            8.2394e-01,  3.0478e-01,  1.1288e+00,  7.6737e-01,  1.7017e+00],\n",
      "          [-2.1264e-01, -1.8750e+00, -2.1112e+00,  2.4271e-01, -5.3580e-01,\n",
      "            5.8242e-01, -9.6039e-01,  2.9491e-01,  4.2169e-01, -2.5280e-01],\n",
      "          [-3.3099e-01, -7.0068e-01, -2.2981e-01,  1.5504e+00, -4.4323e-01,\n",
      "            1.3953e+00, -2.0092e+00,  1.4159e-01,  1.7603e+00,  1.3945e+00],\n",
      "          [ 6.9160e-01,  3.9457e-01, -6.2283e-01, -9.3275e-01,  4.1003e-01,\n",
      "           -2.0210e+00,  9.8246e-01,  2.0212e-01,  6.6417e-01,  1.0909e+00],\n",
      "          [ 2.9392e-01, -5.8461e-01,  5.7005e-01,  1.6243e-02, -9.4424e-01,\n",
      "           -6.2767e-03,  1.1252e+00, -1.2797e+00, -4.2013e-04,  9.2083e-01],\n",
      "          [ 8.4634e-01, -1.7510e+00,  1.5702e+00,  1.6823e+00, -2.1868e-01,\n",
      "            4.4612e-01,  4.7490e-01, -1.4383e+00,  1.2813e+00, -3.7939e-01],\n",
      "          [-9.2285e-01,  2.2049e-01, -1.3121e+00,  5.8053e-01, -1.4704e+00,\n",
      "           -2.8910e-01, -1.2073e+00,  2.0834e+00, -1.5668e+00,  2.3620e-01],\n",
      "          [ 4.6905e-01, -8.1776e-02, -2.3895e+00, -2.6361e+00, -1.2031e+00,\n",
      "           -1.5069e+00, -1.9449e-01, -6.4313e-01,  2.8830e-01, -1.1075e+00],\n",
      "          [-5.6273e-01,  5.7632e-01,  6.6033e-01, -2.9893e+00,  3.3569e-01,\n",
      "           -1.0924e+00, -2.7458e-01, -1.6318e-01,  3.2703e-01, -2.4374e+00]]]])\n",
      "torch.Size([1, 1, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a 2D convolutional layer with dilation\n",
    "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, dilation=2)\n",
    "print(conv_layer)\n",
    "\n",
    "# Input tensor of shape (batch_size, channels, height, width)\n",
    "input_tensor = torch.randn(1, 1, 10, 10)\n",
    "print(input_tensor)\n",
    "\n",
    "# Apply the convolutional layer\n",
    "output_tensor = conv_layer(input_tensor)\n",
    "\n",
    "print(output_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from typing import Tuple, Union\n",
    "\n",
    "\n",
    "class CausalConv3d(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size: int = 3,\n",
    "        stride: Union[int, Tuple[int]] = 1,\n",
    "        dilation: int = 1,\n",
    "        groups: int = 1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        kernel_size = (kernel_size, kernel_size, kernel_size)\n",
    "        self.time_kernel_size = kernel_size[0]\n",
    "\n",
    "        dilation = (dilation, 1, 1)\n",
    "\n",
    "        height_pad = kernel_size[1] // 2\n",
    "        width_pad = kernel_size[2] // 2\n",
    "        padding = (0, height_pad, width_pad)\n",
    "\n",
    "        self.conv = nn.Conv3d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=stride,\n",
    "            dilation=dilation,\n",
    "            padding=padding,\n",
    "            padding_mode=\"zeros\",\n",
    "            groups=groups,\n",
    "        )\n",
    "\n",
    "    def forward(self, x, causal: bool = True):\n",
    "        print(\"x\", x.shape)  # -> ([2, 3, 10, 20, 20]) -> (Batch_size, channels, depth, height, width)\n",
    "        print(\"x details: \", x[:, :, :1, :, :].shape)  # ([2, 3, 1, 20, 20])\n",
    "        \n",
    "        if causal:\n",
    "            first_frame_pad = x[:, :, :1, :, :].repeat(\n",
    "                (1, 1, self.time_kernel_size - 1, 1, 1)   \n",
    "            )\n",
    "            print(\"first frame padding\", first_frame_pad.shape) # ([2, 3, 2, 20, 20])\n",
    "            \n",
    "            detail_first_frame_pad = x[:, :, :1, :, :]  # ([2, 3, 1, 20, 20])\n",
    "            detail_first_frame_pad = detail_first_frame_pad.repeat(1, 1, self.time_kernel_size - 1, 1, 1)  #  kernel_size -> 3 - 1 = 2 \n",
    "            print(\"detail first frame padding: \", detail_first_frame_pad.shape) # ([2, 3, 2, 20, 20])\n",
    "            \n",
    "            x = torch.cat((first_frame_pad, x), dim=2)\n",
    "            print(\"x\", x.shape)  # ([2, 3, 12, 20, 20]), ([2, 3, 10, 20, 20])\n",
    "            \n",
    "            print(\"first frame padding in x: \", x[0].shape) # ([3, 12, 20, 20])\n",
    "            print(\"first frame padding in x1: \", x[1].shape)\n",
    "           \n",
    "            \n",
    "        else:\n",
    "            first_frame_pad = x[:, :, :1, :, :].repeat(\n",
    "                (1, 1, (self.time_kernel_size - 1) // 2, 1, 1)\n",
    "            )\n",
    "            print(f\"first frame padding: {first_frame_pad.shape}\")   # ([2, 3, 1, 20, 20])\n",
    "            \n",
    "            last_frame_pad = x[:, :, -1:, :, :].repeat(\n",
    "                (1, 1, (self.time_kernel_size - 1) // 2, 1, 1)\n",
    "            )\n",
    "            \n",
    "            print(\"last frame padding\", last_frame_pad.shape)\n",
    "            \n",
    "            \n",
    "            x = torch.cat((first_frame_pad, x, last_frame_pad), dim=2)\n",
    "            print(\"x\", x.shape)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def weight(self):\n",
    "        return self.conv.weight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Tensor:  torch.Size([2, 3, 10, 20, 20])\n",
      "causal conv3d layer:  CausalConv3d(\n",
      "  (conv): Conv3d(3, 6, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1))\n",
      ")\n",
      "x torch.Size([2, 3, 10, 20, 20])\n",
      "x details:  torch.Size([2, 3, 1, 20, 20])\n",
      "first frame padding torch.Size([2, 3, 2, 20, 20])\n",
      "detail first frame padding:  torch.Size([2, 3, 2, 20, 20])\n",
      "x torch.Size([2, 3, 12, 20, 20])\n",
      "first frame padding in x:  torch.Size([3, 12, 20, 20])\n",
      "first frame padding in x1:  torch.Size([3, 12, 20, 20])\n",
      "x torch.Size([2, 3, 10, 20, 20])\n",
      "x details:  torch.Size([2, 3, 1, 20, 20])\n",
      "first frame padding: torch.Size([2, 3, 1, 20, 20])\n",
      "last frame padding torch.Size([2, 3, 1, 20, 20])\n",
      "x torch.Size([2, 3, 12, 20, 20])\n",
      "Output Shape with Causal Padding: torch.Size([2, 6, 10, 20, 20])\n",
      "Output Shape with Non-Causal Padding: torch.Size([2, 6, 10, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "# Sample Input Tensor\n",
    "batch_size = 2\n",
    "channels = 3\n",
    "depth = 10  # Time dimension\n",
    "height = 20\n",
    "width = 20\n",
    "\n",
    "# Random tensor with the shape (batch_size, channels, depth, height, width)\n",
    "input_tensor = torch.randn(batch_size, channels, depth, height, width)\n",
    "print(\"input Tensor: \", input_tensor.shape)\n",
    "\n",
    "# Instantiate the CausalConv3d layer\n",
    "causal_conv3d_layer = CausalConv3d(in_channels=channels, out_channels=6, kernel_size=3)\n",
    "print(\"causal conv3d layer: \", causal_conv3d_layer)\n",
    "\n",
    "# Apply the causal convolution with causal=True\n",
    "output_tensor_causal = causal_conv3d_layer(input_tensor, causal=True)\n",
    "\n",
    "# Apply the causal convolution with causal=False\n",
    "output_tensor_non_causal = causal_conv3d_layer(input_tensor, causal=False)\n",
    "\n",
    "# Print the shapes of the output tensors\n",
    "print(\"Output Shape with Causal Padding:\", output_tensor_causal.shape)\n",
    "print(\"Output Shape with Non-Causal Padding:\", output_tensor_non_causal.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formula of dialation: R + (R - 1) x (d - 1)\n",
    "# R - currnel size \n",
    "# d - dilation \n",
    "\n",
    "3 + ( 3 - 1)* (2 - 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn.init.kaiming_uniform_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight: tensor([[7.9278e+28, 9.6269e-43, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([[ 0.3333,  0.1480, -0.4159, -0.4272,  0.2004],\n",
      "        [-0.2514,  0.2156,  0.3105, -0.3438,  0.2856],\n",
      "        [-0.3329, -0.2017, -0.0799, -0.3891, -0.3182]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "weight = torch.empty(3, 5)\n",
    "print(f\"Weight: {weight}\")\n",
    "nn.init.kaiming_uniform_(weight, a=math.sqrt(5))\n",
    "print(weight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.init._calculate_fan_in_and_fan_out(self.weight1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight tensor([[[[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]],\n",
      "\n",
      "\n",
      "         [[[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]],\n",
      "\n",
      "          [[0., 0., 0.],\n",
      "           [0., 0., 0.],\n",
      "           [0., 0., 0.]]]]])\n",
      "Fan-In: 81\n",
      "Fan-Out: 432\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "\n",
    "# (out_channels, in_channels, depth, height, width)\n",
    "weight = torch.empty(16, 3, 3, 3, 3)\n",
    "print(\"weight\", weight)\n",
    "\n",
    "fan_in, fan_out = nn.init._calculate_fan_in_and_fan_out(weight)\n",
    "print(\"Fan-In:\", fan_in)\n",
    "print(\"Fan-Out:\", fan_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 3, 3, 3])\n",
      "torch.Size([1, 16, 30, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a 3D convolutional layer\n",
    "conv3d_layer = nn.Conv3d(in_channels=3, out_channels=16, kernel_size=(3, 3, 3))\n",
    "\n",
    "# Print the shape of the weight tensor\n",
    "print(conv3d_layer.weight.shape)  # Should output torch.Size([16, 3, 3, 3, 3])\n",
    "\n",
    "# Example input tensor (e.g., a batch of 3D volumes)\n",
    "input_tensor = torch.randn(1, 3, 32, 32, 32)  # shape (batch_size, in_channels, depth, height, width)\n",
    "\n",
    "# Apply the convolutional layer to the input tensor\n",
    "output_tensor = conv3d_layer(input_tensor)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(output_tensor.shape)  # Output shape depends on stride, padding, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
